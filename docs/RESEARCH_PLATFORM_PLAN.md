# Дорожная карта превращения Open Deep Research в полноценную исследовательскую платформу

Цель: развить продукт в инструмент для исследователей и учёных (в т. ч. в РФ), позволяющий формировать гипотезы, управлять источниками, проводить валидацию и готовить публикации. Опора на самодостаточную инфраструктуру и гибкость под разные методологии исследований.

## Вектор развития и принципы

- **Научная воспроизводимость**: цитируемость, версия источников, прозрачность пайплайнов (data provenance).
- **Работа с русскоязычными ресурсами**: интеграция с РИНЦ/КиберЛенинкой/eLIBRARY, госреестрами, локальными архивами; поддержка кириллического поиска.
- **Модульность**: отдельные сервисы для сбора данных, векторизации, графа знаний, визуализации, коллаборации.
- **Безопасность и приватность**: on-prem развёртывание, контроль доступа по ролям (RBAC/ABAC), аудит действий.
- **Методологическая гибкость**: сценарии для прикладных исследований, обзоров литературы, построения гипотез, экспериментов и мета-анализа.

## Целевой функционал

- **Поиск и агрегирование источников**: веб, научные индексы, библиографические БД, патенты, нормативные акты, ГОСТы; поддержка прокси/блокировок.
- **Управление гипотезами и вопросами**: дерево гипотез, статус проверки, связка с экспериментами и источниками.
- **Граф знаний**: сущности (авторы, организации, понятия), связи и веса; версионирование и источники доказательств.
- **Качество данных**: дедупликация, оценка достоверности, анти-плагиат/Similarity, маркировка уровня доказательств.
- **Коллаборация**: рабочие пространства, роли (исследователь, руководитель, ревьюер), комментарии, задачи, change-log.
- **Пайплайны анализа**: конвейеры для парсинга, векторизации (ru-ориентированные модели), кластеризации, тематического моделирования, временных рядов.
- **Экспорт и публикация**: отчёты с источниками, шаблоны статей (GOST, IEEE), библиографии (BibTeX/ГОСТ), выгрузка данных (CSV/JSON/RIS).
- **Наблюдаемость и комплаенс**: аудит событий, контроль версий данных/моделей, DPIA/152-ФЗ соответствие.

## Архитектурные компоненты

- **Сбор данных**: краулер (Playwright/Puppeteer) + антибот; коннекторы к РИНЦ/eLIBRARY/КиберЛенинке; импорт PDF/EPUB; очереди задач.
- **Парсинг и нормализация**: извлечение метаданных (DOI, авторы, аффилиации), таблицы/графики (Camelot/Tabula), очистка HTML.
- **Хранилища**:
  - OLTP: Postgres (версии сущностей, ACL).
  - Объекты: MinIO/S3 (PDF, вложения, датасеты).
  - Векторное: Qdrant/Weaviate/Vald (ru-friendly embedding-модели, напр. sbert/ruBERT, mGTE).
  - Граф: Neo4j/ArangoDB/Postgres+pgvector+pg_graph.
- **Обработка**: воркфлоу-оркестратор (Temporal/Airflow) для цепочек «краул → парсинг → векторизация → граф → QC».
- **LLM-уровень**: планирование исследований, извлечение сущностей, черновики отчетов; прокси-трассировка (Langfuse/OTel). LLM остаётся внешним.
- **Поиск и аналитика**: комбинированный поиск (BM25 + векторный + графовые обходы); фасеты по источникам/годам/типам; тематические карты.
- **Интерфейс исследователя**: конструктор запросов, редактор гипотез, инспектор источников, графовые визуализации (D3/Graphin), воркспейсы и ревью.

## Дорожная карта по этапам

1. **Foundations (1–2 спринта)**
   - Разделить сервисы: фронтенд/бэкенд/воркеры/краулер. Настроить CI/CD и observability.
   - Добавить базовые роли и аудито-лог действий.
   - Ввести версионирование источников и нормализованную схему (источник ↔ сущности ↔ цитаты).
2. **Сбор и нормализация (2–3 спринта)**
   - Краулер с поддержкой русскоязычных сайтов и антибот-стратегиями; очередь задач.
   - Коннекторы к РИНЦ/КиберЛенинке/eLIBRARY (если API нет — headless scraping с кэшированием).
   - Парсинг PDF/HTML, извлечение метаданных, проверка дубликатов и уровня качества источника.
3. **Поиск и знаниевая модель (3–4 спринта)**
   - Векторное хранилище + русскоязычные эмбеддинги; гибридный поиск (BM25+вектор).
   - Пилот графа знаний: авторы/организации/термины, ссылки на источники и уровень доверия.
   - UI: поиск с фасетами, просмотр карточки источника, графовая визуализация связей.
4. **Гипотезы, эксперименты, коллаборация (3 спринта)**
   - Модель гипотез (статусы, критерии проверки, связанные источники/эксперименты).
   - Трекинг задач/комментариев, ролевая модель (руководитель/исследователь/ревьюер).
   - Экспорт отчётов (ГОСТ/IEEE шаблоны), генерация библиографий.
5. **Качество, соответствие и масштаб (2–3 спринта)**
   - Автоматические проверки качества (анти-плагиат, уровень доказательности, дедупликация).
   - Observability: мониторинг пайплайнов, SLA источников, контроль версий моделей.
   - Локализация/интернационализация, оптимизация стоимости инфраструктуры.
6. **Продвинутые исследования (итеративно)**
   - Автоматический мета-анализ, выявление пробелов в литературе (gap detection).
   - Управление экспериментами/данными (MLOps/MLflow/DVC для воспроизводимости).
   - Полнотекстовый офлайн-индекс ключевых доменов, обновление по расписанию.

## Быстрые выигрыши (в ближайший релиз)

- Добавить карточку «Гипотезы» в UI с привязкой к источникам и статусом проверки.
- Включить гибридный поиск (BM25 + векторный) по сохранённым материалам.
- Запустить прототип графовой визуализации связей между источниками/терминами.
- Настроить импорт PDF/HTML с извлечением метаданных и ссылок.
- Подготовить шаблон отчёта по ГОСТ и экспорт BibTeX/RIS.

## Метрики успеха

- Покрытие ключевых русскоязычных источников (доля индекса РИНЦ/КиберЛенинка в индексе).
- Время от запроса до черновика отчёта с цитатами (<10 мин для обзора литературы).
- Количество проверенных гипотез/месяц и среднее время ревью.
- Коэффициент дедупликации и качество извлечённых метаданных (precision/recall).
- Uptime пайплайнов и доля успешно завершённых воркфлоу.

## Требования к соответствию и приватности

- Соответствие 152-ФЗ: хранение/обработка ПДн в РФ, шифрование «в покое» и «на лету», журналирование доступа.
- Управление ключами (KMS или HashiCorp Vault), секреты через sealed-secrets/parameter store.
- Контроль лицензий источников, этические ограничения на веб-скрейпинг и соблюдение robots.txt.

## Организация команды

- Роли: архитектор данных, инженер по сбору/парсингу, ML/IR инженер, бэкенд, фронтенд, DevOps/SRE, специалист по комплаенсу.
- Процессы: RFC для изменений схем/пайплайнов, демо каждые 2 недели, тестовые стенды для краулера и LLM-подсистемы.

## Интеграция с текущим проектом

- Сохранить существующие возможности (планирование и отчёты) как пользовательский слой поверх новых сервисов.
- Постепенно переводить сбор данных с внешнего Exa на собственный краулер/индекс.
- Расширить UI: панель гипотез, каталог источников, граф связей, аудит действий.
